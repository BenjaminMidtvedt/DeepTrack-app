{"undoable":{"past":[[{"kind":"E","path":["items",99,"value"],"lhs":"lambda image: (np.real(image), np.imag(imagec))","rhs":"lambda image: (np.real(image), np.imag(image))"}],[{"kind":"E","path":["items",98,"expand"],"lhs":true,"rhs":false}],[{"kind":"E","path":["items",82,"value"],"lhs":"np.random.randn() * 10","rhs":"np.random.randn() * 100"}],"@@easy-redux-undo/GROUPBEGIN",[{"kind":"A","path":["items"],"index":100,"item":{"kind":"N","rhs":{"items":[],"name":"ConditionalSetProperty","expand":true,"class":"feature","key":"features","type":"ConditionalSetProperty","description":" Conditionally overrides the properties of child features\n    \n    ","index":100}}},{"kind":"A","path":["items",15,"items"],"index":1,"item":{"kind":"N","rhs":79}},{"kind":"E","path":["items",15,"items",0],"lhs":79,"rhs":100}],[{"kind":"A","path":["items"],"index":101,"item":{"kind":"N","rhs":{"items":[],"name":"feature","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"feature":["Feature","\n        The child feature"],"condition":["str","\n        The name of the conditional property"]},"index":101}}},{"kind":"A","path":["items",100,"items"],"index":0,"item":{"kind":"N","rhs":101}}],[{"kind":"A","path":["items"],"index":102,"item":{"kind":"N","rhs":{"items":[],"name":"condition","expand":true,"class":"property","value":"'is_label'","descriptions":{"feature":["Feature","\n        The child feature"],"condition":["str","\n        The name of the conditional property"]},"index":102}}},{"kind":"A","path":["items",100,"items"],"index":1,"item":{"kind":"N","rhs":102}}],"@@easy-redux-undo/GROUPEND","@@easy-redux-undo/GROUPBEGIN",[{"kind":"A","path":["items",101,"items"],"index":0,"item":{"kind":"N","rhs":79}},{"kind":"A","path":["items",15,"items"],"index":1,"item":{"kind":"D","lhs":79}}],[{"kind":"A","path":["items"],"index":103,"item":{"kind":"N","rhs":{"items":[],"name":"","expand":true,"class":"property","value":"","index":103}}},{"kind":"A","path":["items",100,"items"],"index":2,"item":{"kind":"N","rhs":103}}],[{"kind":"E","path":["items",103,"expand"],"lhs":true,"rhs":false}],[{"kind":"E","path":["items",103,"name"],"lhs":"","rhs":"z"}],[{"kind":"E","path":["items",103,"expand"],"lhs":false,"rhs":true}],[{"kind":"E","path":["items",103,"value"],"lhs":"","rhs":"0"}],[{"kind":"E","path":["items",94,"value"],"lhs":"(0, 0, 128, 128)","rhs":"(0, 0, 5, 128)"}],[{"kind":"E","path":["items",94,"value"],"lhs":"(0, 0, 5, 128)","rhs":"(0, 0, , 128)"}],[{"kind":"E","path":["items",94,"value"],"lhs":"(0, 0, , 128)","rhs":"(0, 0, 6, 128)"}],[{"kind":"E","path":["items",94,"value"],"lhs":"(0, 0, 6, 128)","rhs":"(0, 0, 64, 128)"}],[{"kind":"E","path":["items",94,"value"],"lhs":"(0, 0, 64, 128)","rhs":"(0, 0, 64, 12)"}],[{"kind":"E","path":["items",94,"value"],"lhs":"(0, 0, 64, 12)","rhs":"(0, 0, 64, 1)"}],[{"kind":"E","path":["items",94,"value"],"lhs":"(0, 0, 64, 1)","rhs":"(0, 0, 64, )"}],[{"kind":"E","path":["items",94,"value"],"lhs":"(0, 0, 64, )","rhs":"(0, 0, 64, 6)"}],[{"kind":"E","path":["items",94,"value"],"lhs":"(0, 0, 64, 6)","rhs":"(0, 0, 64, 64)"}],[{"kind":"E","path":["items",80,"value"],"lhs":"1e-7 + np.random.rand() * 9e-7","rhs":"4e-7 + np.random.rand() * 9e-7"}],[{"kind":"E","path":["items",80,"value"],"lhs":"4e-7 + np.random.rand() * 9e-7","rhs":"4e-7 + np.random.rand() * 6e-7"}],[{"kind":"E","path":["items",81,"value"],"lhs":"(64, 64)","rhs":"(3, 64)"}],[{"kind":"E","path":["items",81,"value"],"lhs":"(3, 64)","rhs":"(32, 64)"}],[{"kind":"E","path":["items",81,"value"],"lhs":"(32, 64)","rhs":"(32, 3)"}],[{"kind":"E","path":["items",81,"value"],"lhs":"(32, 3)","rhs":"(32, 32)"}],[{"kind":"E","path":["items",92,"value"],"lhs":"1","rhs":"2"}],[{"kind":"E","path":["items",92,"value"],"lhs":"2","rhs":"4"}],[{"kind":"E","path":["items",92,"value"],"lhs":"4","rhs":"1"}],"@@easy-redux-undo/GROUPBEGIN",[{"kind":"E","path":["items",97,"expand"],"lhs":true,"rhs":false}],[{"kind":"E","path":["items",97,"expand"],"lhs":false,"rhs":true}],[{"kind":"E","path":["items",97,"expand"],"lhs":true,"rhs":false}],[{"kind":"E","path":["items",97,"expand"],"lhs":false,"rhs":true}],[{"kind":"E","path":["items",97,"name"],"lhs":"Lambda","rhs":""}],[{"kind":"E","path":["items",97,"name"],"lhs":"","rhs":"C"}],[{"kind":"E","path":["items",97,"name"],"lhs":"C","rhs":"Co"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Co","rhs":"Com"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Com","rhs":"Comp"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Comp","rhs":"Compl"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Compl","rhs":"Comple"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Comple","rhs":"Complex"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Complex","rhs":"ComplexT"}],[{"kind":"E","path":["items",97,"name"],"lhs":"ComplexT","rhs":"ComplexTo"}],[{"kind":"E","path":["items",97,"name"],"lhs":"ComplexTo","rhs":"ComplexToF"}],[{"kind":"E","path":["items",97,"name"],"lhs":"ComplexToF","rhs":"ComplexToFi"}],[{"kind":"E","path":["items",97,"name"],"lhs":"ComplexToFi","rhs":"ComplexToFie"}],[{"kind":"E","path":["items",97,"name"],"lhs":"ComplexToFie","rhs":"ComplexToFiel"}],[{"kind":"E","path":["items",97,"name"],"lhs":"ComplexToFiel","rhs":"ComplexToField"}],[{"kind":"E","path":["items",97,"name"],"lhs":"ComplexToField","rhs":"ComplexToFiel"}],[{"kind":"E","path":["items",97,"name"],"lhs":"ComplexToFiel","rhs":"ComplexToFie"}],[{"kind":"E","path":["items",97,"name"],"lhs":"ComplexToFie","rhs":"ComplexToFi"}],[{"kind":"E","path":["items",97,"name"],"lhs":"ComplexToFi","rhs":"ComplexToF"}],[{"kind":"E","path":["items",97,"name"],"lhs":"ComplexToF","rhs":"ComplexTo"}],[{"kind":"E","path":["items",97,"name"],"lhs":"ComplexTo","rhs":"ComplexT"}],[{"kind":"E","path":["items",97,"name"],"lhs":"ComplexT","rhs":"Complex"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Complex","rhs":"Comple"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Comple","rhs":"Compl"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Compl","rhs":"Comp"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Comp","rhs":"Com"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Com","rhs":"Co"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Co","rhs":"C"}],[{"kind":"E","path":["items",97,"name"],"lhs":"C","rhs":""}],[{"kind":"E","path":["items",97,"name"],"lhs":"","rhs":"S"}],[{"kind":"E","path":["items",97,"name"],"lhs":"S","rhs":"Sp"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Sp","rhs":"Spl"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Spl","rhs":"Splo"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Splo","rhs":"Spl"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Spl","rhs":"Spli"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Spli","rhs":"Split"}],[{"kind":"E","path":["items",97,"name"],"lhs":"Split","rhs":"SplitC"}],[{"kind":"E","path":["items",97,"name"],"lhs":"SplitC","rhs":"SplitCo"}],[{"kind":"E","path":["items",97,"name"],"lhs":"SplitCo","rhs":"SplitCom"}],[{"kind":"E","path":["items",97,"name"],"lhs":"SplitCom","rhs":"SplitComp"}],[{"kind":"E","path":["items",97,"name"],"lhs":"SplitComp","rhs":"SplitCompl"}],[{"kind":"E","path":["items",97,"name"],"lhs":"SplitCompl","rhs":"SplitComple"}],[{"kind":"E","path":["items",97,"name"],"lhs":"SplitComple","rhs":"SplitComplex"}],[{"kind":"E","path":["items",97,"name"],"lhs":"SplitComplex","rhs":"SplitComplexI"}],[{"kind":"E","path":["items",97,"name"],"lhs":"SplitComplexI","rhs":"SplitComplex"}],[{"kind":"E","path":["items",89,"value"],"lhs":"1","rhs":"10"}],[{"kind":"E","path":["items",82,"value"],"lhs":"np.random.randn() * 100","rhs":"np.random.randn() * 10"}],[{"kind":"E","path":["items",87,"value"],"lhs":"0.7","rhs":"1"}],[{"kind":"E","path":["items",87,"value"],"lhs":"1","rhs":"1."}],[{"kind":"A","path":["items"],"index":106,"item":{"kind":"N","rhs":{"items":[],"name":"get_field","expand":true,"class":"property","value":"lambda image: (np.real(image), np.imag(image))","index":99}}},{"kind":"A","path":["items"],"index":105,"item":{"kind":"N","rhs":{"items":[],"name":"function","expand":false,"class":"property","value":"lambda image: np.concatenate(get_field(image), axis=-1)","descriptions":{"function":["Callable[Image]","\n        Function that takes the current image as first input "]},"index":98}}},{"kind":"A","path":["items"],"index":104,"item":{"kind":"N","rhs":{"items":[105,106],"name":"SplitComplex","expand":true,"class":"feature","key":"features","type":"Lambda","description":" Calls a custom function on each image in the input.\n\n    Note that the property `function` needs to be wrapped in an\n    outer layer function. The outer layer function can depend on\n    other properties, while the inner layer function accepts an\n    image as input.\n\n    ","index":104}}},{"kind":"A","path":["items",16,"items"],"index":1,"item":{"kind":"N","rhs":104}}],[{"kind":"E","path":["items",104],"lhs":{"items":[105,106],"name":"SplitComplex","expand":true,"class":"feature","key":"features","type":"Lambda","description":" Calls a custom function on each image in the input.\n\n    Note that the property `function` needs to be wrapped in an\n    outer layer function. The outer layer function can depend on\n    other properties, while the inner layer function accepts an\n    image as input.\n\n    ","index":104},"rhs":null},{"kind":"E","path":["items",44],"lhs":{"items":[],"name":"pupil","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":44},"rhs":null},{"kind":"E","path":["items",43],"lhs":{"items":[],"name":"output_region","expand":false,"class":"property","value":"(0, 0, 128, 128)","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":43},"rhs":null},{"kind":"E","path":["items",42],"lhs":{"items":[],"name":"padding","expand":true,"class":"property","value":"(10, 10, 10, 10)","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":42},"rhs":null},{"kind":"E","path":["items",41],"lhs":{"items":[],"name":"upscale","expand":true,"class":"property","value":"1","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":41},"rhs":null},{"kind":"E","path":["items",40],"lhs":{"items":[],"name":"refractive_index_medium","expand":true,"class":"property","value":"1.33","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":40},"rhs":null},{"kind":"E","path":["items",39],"lhs":{"items":[],"name":"resolution","expand":true,"class":"property","value":"(1e-06, 1e-06, 1e-06)","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":39},"rhs":null},{"kind":"E","path":["items",38],"lhs":{"items":[],"name":"magnification","expand":true,"class":"property","value":"5","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":38},"rhs":null},{"kind":"E","path":["items",37],"lhs":{"items":[],"name":"wavelength","expand":true,"class":"property","value":"6.6e-07","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":37},"rhs":null},{"kind":"E","path":["items",36],"lhs":{"items":[],"name":"NA","expand":true,"class":"property","value":"0.7","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":36},"rhs":null},{"kind":"A","path":["items",16,"items"],"index":1,"item":{"kind":"D","lhs":104}}],[{"kind":"A","path":["items"],"index":109,"item":{"kind":"N","rhs":{"items":[],"name":"get_field","expand":true,"class":"property","value":"lambda image: (np.real(image), np.imag(image))","index":99}}},{"kind":"A","path":["items"],"index":108,"item":{"kind":"N","rhs":{"items":[],"name":"function","expand":false,"class":"property","value":"lambda image: np.concatenate(get_field(image), axis=-1)","descriptions":{"function":["Callable[Image]","\n        Function that takes the current image as first input "]},"index":98}}},{"kind":"A","path":["items"],"index":107,"item":{"kind":"N","rhs":{"items":[108,109],"name":"SplitComplex","expand":true,"class":"feature","key":"features","type":"Lambda","description":" Calls a custom function on each image in the input.\n\n    Note that the property `function` needs to be wrapped in an\n    outer layer function. The outer layer function can depend on\n    other properties, while the inner layer function accepts an\n    image as input.\n\n    ","index":107}}},{"kind":"A","path":["items",4,"items"],"index":2,"item":{"kind":"N","rhs":107}}],[{"kind":"E","path":["items",1,"expand"],"lhs":true,"rhs":false}],[{"kind":"A","path":["items"],"index":112,"item":{"kind":"N","rhs":{"items":[],"name":"get_field","expand":true,"class":"property","value":"lambda image: (np.real(image), np.imag(image))","index":99}}},{"kind":"A","path":["items"],"index":111,"item":{"kind":"N","rhs":{"items":[],"name":"function","expand":false,"class":"property","value":"lambda image: np.concatenate(get_field(image), axis=-1)","descriptions":{"function":["Callable[Image]","\n        Function that takes the current image as first input "]},"index":98}}},{"kind":"A","path":["items"],"index":110,"item":{"kind":"N","rhs":{"items":[111,112],"name":"SplitComplex","expand":true,"class":"feature","key":"features","type":"Lambda","description":" Calls a custom function on each image in the input.\n\n    Note that the property `function` needs to be wrapped in an\n    outer layer function. The outer layer function can depend on\n    other properties, while the inner layer function accepts an\n    image as input.\n\n    ","index":110}}},{"kind":"A","path":["items",7,"items"],"index":1,"item":{"kind":"N","rhs":110}}],[{"kind":"A","path":["items"],"index":115,"item":{"kind":"N","rhs":{"items":[],"name":"get_field","expand":true,"class":"property","value":"lambda image: (np.real(image), np.imag(image))","index":99}}},{"kind":"A","path":["items"],"index":114,"item":{"kind":"N","rhs":{"items":[],"name":"function","expand":false,"class":"property","value":"lambda image: np.concatenate(get_field(image), axis=-1)","descriptions":{"function":["Callable[Image]","\n        Function that takes the current image as first input "]},"index":98}}},{"kind":"A","path":["items"],"index":113,"item":{"kind":"N","rhs":{"items":[114,115],"name":"SplitComplex","expand":true,"class":"feature","key":"features","type":"Lambda","description":" Calls a custom function on each image in the input.\n\n    Note that the property `function` needs to be wrapped in an\n    outer layer function. The outer layer function can depend on\n    other properties, while the inner layer function accepts an\n    image as input.\n\n    ","index":113}}},{"kind":"A","path":["items",7,"items"],"index":2,"item":{"kind":"N","rhs":113}}],"@@easy-redux-undo/GROUPBEGIN",[{"kind":"E","path":["items",7,"items",2],"lhs":113,"rhs":110},{"kind":"E","path":["items",7,"items",1],"lhs":110,"rhs":113}],[{"kind":"E","path":["items",98,"expand"],"lhs":false,"rhs":true}],[{"kind":"E","path":["items",98,"expand"],"lhs":true,"rhs":false}],[{"kind":"E","path":["items",98,"expand"],"lhs":false,"rhs":true}],[{"kind":"A","path":["items"],"index":118,"item":{"kind":"N","rhs":{"items":[],"name":"get_field","expand":true,"class":"property","value":"lambda image: (np.real(image), np.imag(image))","index":118}}},{"kind":"A","path":["items"],"index":117,"item":{"kind":"N","rhs":{"items":[],"name":"function","expand":false,"class":"property","value":"lambda image: np.concatenate(get_field(image), axis=-1)","descriptions":{"function":["Callable[Image]","\n        Function that takes the current image as first input "]},"index":117}}},{"kind":"A","path":["items"],"index":116,"item":{"kind":"N","rhs":{"items":[117,118],"name":"SplitComplex","expand":true,"class":"feature","key":"features","type":"Lambda","description":" Calls a custom function on each image in the input.\n\n    Note that the property `function` needs to be wrapped in an\n    outer layer function. The outer layer function can depend on\n    other properties, while the inner layer function accepts an\n    image as input.\n\n    ","index":116}}},{"kind":"A","path":["items",7,"items"],"index":3,"item":{"kind":"N","rhs":110}},{"kind":"E","path":["items",7,"items",2],"lhs":110,"rhs":113},{"kind":"E","path":["items",7,"items",1],"lhs":113,"rhs":116}],[{"kind":"E","path":["items",118,"value"],"lhs":"lambda image: (np.real(image), np.imag(image))","rhs":"lambda image: (np.real(image), np.imag(image))a"}],[{"kind":"E","path":["items",113],"lhs":{"items":[114,115],"name":"SplitComplex","expand":true,"class":"feature","key":"features","type":"Lambda","description":" Calls a custom function on each image in the input.\n\n    Note that the property `function` needs to be wrapped in an\n    outer layer function. The outer layer function can depend on\n    other properties, while the inner layer function accepts an\n    image as input.\n\n    ","index":113},"rhs":null},{"kind":"E","path":["items",106],"lhs":{"items":[],"name":"get_field","expand":true,"class":"property","value":"lambda image: (np.real(image), np.imag(image))","index":99},"rhs":null},{"kind":"E","path":["items",105],"lhs":{"items":[],"name":"function","expand":false,"class":"property","value":"lambda image: np.concatenate(get_field(image), axis=-1)","descriptions":{"function":["Callable[Image]","\n        Function that takes the current image as first input "]},"index":98},"rhs":null},{"kind":"A","path":["items",7,"items"],"index":3,"item":{"kind":"D","lhs":110}},{"kind":"E","path":["items",7,"items",2],"lhs":113,"rhs":110}],[{"kind":"E","path":["items",115],"lhs":{"items":[],"name":"get_field","expand":true,"class":"property","value":"lambda image: (np.real(image), np.imag(image))","index":99},"rhs":null},{"kind":"E","path":["items",114],"lhs":{"items":[],"name":"function","expand":false,"class":"property","value":"lambda image: np.concatenate(get_field(image), axis=-1)","descriptions":{"function":["Callable[Image]","\n        Function that takes the current image as first input "]},"index":98},"rhs":null},{"kind":"E","path":["items",110],"lhs":{"items":[111,112],"name":"SplitComplex","expand":true,"class":"feature","key":"features","type":"Lambda","description":" Calls a custom function on each image in the input.\n\n    Note that the property `function` needs to be wrapped in an\n    outer layer function. The outer layer function can depend on\n    other properties, while the inner layer function accepts an\n    image as input.\n\n    ","index":110},"rhs":null},{"kind":"A","path":["items",7,"items"],"index":2,"item":{"kind":"D","lhs":110}}],[{"kind":"E","path":["items",116],"lhs":{"items":[117,118],"name":"SplitComplex","expand":true,"class":"feature","key":"features","type":"Lambda","description":" Calls a custom function on each image in the input.\n\n    Note that the property `function` needs to be wrapped in an\n    outer layer function. The outer layer function can depend on\n    other properties, while the inner layer function accepts an\n    image as input.\n\n    ","index":116},"rhs":null},{"kind":"E","path":["items",112],"lhs":{"items":[],"name":"get_field","expand":true,"class":"property","value":"lambda image: (np.real(image), np.imag(image))","index":99},"rhs":null},{"kind":"E","path":["items",111],"lhs":{"items":[],"name":"function","expand":false,"class":"property","value":"lambda image: np.concatenate(get_field(image), axis=-1)","descriptions":{"function":["Callable[Image]","\n        Function that takes the current image as first input "]},"index":98},"rhs":null},{"kind":"A","path":["items",7,"items"],"index":1,"item":{"kind":"D","lhs":116}}],[{"kind":"A","path":["items"],"index":121,"item":{"kind":"N","rhs":{"items":[],"name":"get_field","expand":true,"class":"property","value":"lambda image: (np.real(image), np.imag(image))","index":121}}},{"kind":"A","path":["items"],"index":120,"item":{"kind":"N","rhs":{"items":[],"name":"function","expand":false,"class":"property","value":"lambda image: np.concatenate(get_field(image), axis=-1)","descriptions":{"function":["Callable[Image]","\n        Function that takes the current image as first input "]},"index":120}}},{"kind":"A","path":["items"],"index":119,"item":{"kind":"N","rhs":{"items":[120,121],"name":"SplitComplex","expand":true,"class":"feature","key":"features","type":"Lambda","description":" Calls a custom function on each image in the input.\n\n    Note that the property `function` needs to be wrapped in an\n    outer layer function. The outer layer function can depend on\n    other properties, while the inner layer function accepts an\n    image as input.\n\n    ","index":119}}},{"kind":"A","path":["items",7,"items"],"index":1,"item":{"kind":"N","rhs":119}}],"@@easy-redux-undo/GROUPBEGIN",[{"kind":"A","path":["items",7,"items"],"index":1,"item":{"kind":"D","lhs":119}},{"kind":"A","path":["items",6,"items"],"index":0,"item":{"kind":"N","rhs":119}}],[{"kind":"E","path":["items",1,"expand"],"lhs":false,"rhs":true}],"@@easy-redux-undo/GROUPBEGIN",[{"kind":"A","path":["items",6,"items"],"index":0,"item":{"kind":"D","lhs":119}},{"kind":"A","path":["items",4,"items"],"index":3,"item":{"kind":"N","rhs":119}}],[{"kind":"E","path":["items",118],"lhs":{"items":[],"name":"get_field","expand":true,"class":"property","value":"lambda image: (np.real(image), np.imag(image))a","index":118},"rhs":null},{"kind":"E","path":["items",117],"lhs":{"items":[],"name":"function","expand":false,"class":"property","value":"lambda image: np.concatenate(get_field(image), axis=-1)","descriptions":{"function":["Callable[Image]","\n        Function that takes the current image as first input "]},"index":117},"rhs":null},{"kind":"E","path":["items",107],"lhs":{"items":[108,109],"name":"SplitComplex","expand":true,"class":"feature","key":"features","type":"Lambda","description":" Calls a custom function on each image in the input.\n\n    Note that the property `function` needs to be wrapped in an\n    outer layer function. The outer layer function can depend on\n    other properties, while the inner layer function accepts an\n    image as input.\n\n    ","index":107},"rhs":null},{"kind":"A","path":["items",4,"items"],"index":3,"item":{"kind":"D","lhs":119}},{"kind":"E","path":["items",4,"items",2],"lhs":107,"rhs":119}]],"present":{"items":[{"items":[1,2],"name":"","expand":true,"index":0},{"items":[3,4,5],"name":"Dataset","expand":true,"load":".dts","class":"root","grabbable":false,"index":1},{"items":[6,7,8],"name":"Model","expand":true,"load":".dtm","class":"root","grabbable":false,"index":2},{"items":[],"name":"Config","expand":true,"class":"featureGroup","grabbable":false,"index":3},{"items":[14,97,119],"name":"Image","expand":true,"class":"featureGroup","grabbable":false,"index":4},{"items":[],"name":"Label","expand":true,"class":"featureGroup","grabbable":false,"index":5},{"items":[],"name":"Preprocess","expand":true,"class":"featureGroup","grabbable":false,"index":6},{"items":[66],"name":"Network","expand":true,"class":"featureGroup","grabbable":false,"index":7},{"items":[],"name":"Postprocess","expand":true,"class":"featureGroup","grabbable":false,"index":8},null,null,null,null,null,{"items":[15,16],"name":"Microscope","expand":true,"class":"feature","key":"optics","type":"Microscope","description":"Image a sample using an optical system.\n\n    Wraps a feature-set defining a sample and a feature-set defining the optics.\n\n    ","index":14},{"items":[100],"name":"sample","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"sample":["Feature","\n        A feature-set resolving a list of images describing the sample to be imaged"],"objective":["Feature","\n        A feature-set defining the optical device that images the sample"]},"index":15},{"items":[86],"name":"objective","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"sample":["Feature","\n        A feature-set resolving a list of images describing the sample to be imaged"],"objective":["Feature","\n        A feature-set defining the optical device that images the sample"]},"index":16},null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,{"items":[67,68,69,70,71,72,73,74,75,76,77,78],"name":"UNet","expand":true,"class":"feature","key":"models","type":"UNet","description":"Creates and compiles a U-Net.\n\n    ","index":66},{"items":[],"name":"input_shape","expand":true,"class":"property","value":"(None, None, 1)","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."]},"index":67},{"items":[],"name":"conv_layers_dimensions","expand":true,"class":"property","value":"(16, 32, 64, 128)","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."]},"index":68},{"items":[],"name":"base_conv_layers_dimensions","expand":true,"class":"property","value":"(128, 128)","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."]},"index":69},{"items":[],"name":"output_conv_layers_dimensions","expand":true,"class":"property","value":"(16, 16)","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."]},"index":70},{"items":[],"name":"dropout","expand":true,"class":"property","value":"","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."]},"index":71},{"items":[],"name":"steps_per_pooling","expand":true,"class":"property","value":"1","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."]},"index":72},{"items":[],"name":"number_of_outputs","expand":true,"class":"property","value":"1","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."]},"index":73},{"items":[],"name":"output_activation","expand":true,"class":"property","value":"","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."]},"index":74},{"items":[],"name":"loss","expand":true,"class":"property","value":"'mae'","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."]},"index":75},{"items":[],"name":"layer_function","expand":true,"class":"property","value":"","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."]},"index":76},{"items":[],"name":"optimizer","expand":true,"class":"property","value":"'adam'","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."]},"index":77},{"items":[],"name":"metrics","expand":true,"class":"property","value":"","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."]},"index":78},{"items":[80,81,82,83,84,85],"name":"Sphere","expand":true,"class":"feature","key":"scatterers","type":"Sphere","description":"Generates a spherical scatterer\n\n    ","index":79},{"items":[],"name":"radius","expand":true,"class":"property","value":"4e-7 + np.random.rand() * 6e-7","descriptions":{"radius":["float","\n        Radius of the sphere in meters."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":80},{"items":[],"name":"position","expand":true,"class":"property","value":"(32, 32)","descriptions":{"radius":["float","\n        Radius of the sphere in meters."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":81},{"items":[],"name":"z","expand":true,"class":"property","value":"np.random.randn() * 10","descriptions":{"radius":["float","\n        Radius of the sphere in meters."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":82},{"items":[],"name":"value","expand":true,"class":"property","value":"1.0","descriptions":{"radius":["float","\n        Radius of the sphere in meters."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":83},{"items":[],"name":"position_unit","expand":true,"class":"property","value":"'pixel'","descriptions":{"radius":["float","\n        Radius of the sphere in meters."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":84},{"items":[],"name":"upsample","expand":true,"class":"property","value":"1","descriptions":{"radius":["float","\n        Radius of the sphere in meters."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":85},{"items":[87,88,89,90,91,92,93,94,95,96],"name":"Brightfield","expand":true,"class":"feature","key":"optics","type":"Brightfield","description":"Images coherently illuminated samples.\n\n    Images samples by creating a discretized volume, where each pixel \n    represents the effective refractive index of that pixel. Light is \n    propagated through the sample iteratively by first propagating the \n    light in the fourier space, followed by a refractive index correction\n    in the real space.\n\n    ","index":86},{"items":[],"name":"NA","expand":true,"class":"property","value":"1.","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":87},{"items":[],"name":"wavelength","expand":true,"class":"property","value":"6.6e-07","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":88},{"items":[],"name":"magnification","expand":true,"class":"property","value":"10","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":89},{"items":[],"name":"resolution","expand":true,"class":"property","value":"(1e-06, 1e-06, 1e-06)","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":90},{"items":[],"name":"refractive_index_medium","expand":true,"class":"property","value":"1.33","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":91},{"items":[],"name":"upscale","expand":true,"class":"property","value":"1","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":92},{"items":[],"name":"padding","expand":true,"class":"property","value":"(10, 10, 10, 10)","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":93},{"items":[],"name":"output_region","expand":true,"class":"property","value":"(0, 0, 64, 64)","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":94},{"items":[],"name":"pupil","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":95},{"items":[],"name":"return_field","expand":true,"class":"property","value":"True","index":96},{"items":[98,99],"name":"SplitComplex","expand":true,"class":"feature","key":"features","type":"Lambda","description":" Calls a custom function on each image in the input.\n\n    Note that the property `function` needs to be wrapped in an\n    outer layer function. The outer layer function can depend on\n    other properties, while the inner layer function accepts an\n    image as input.\n\n    ","index":97},{"items":[],"name":"function","expand":true,"class":"property","value":"lambda image: np.concatenate(get_field(image), axis=-1)","descriptions":{"function":["Callable[Image]","\n        Function that takes the current image as first input "]},"index":98},{"items":[],"name":"get_field","expand":true,"class":"property","value":"lambda image: (np.real(image), np.imag(image))","index":99},{"items":[101,102,103],"name":"ConditionalSetProperty","expand":true,"class":"feature","key":"features","type":"ConditionalSetProperty","description":" Conditionally overrides the properties of child features\n    \n    ","index":100},{"items":[79],"name":"feature","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"feature":["Feature","\n        The child feature"],"condition":["str","\n        The name of the conditional property"]},"index":101},{"items":[],"name":"condition","expand":true,"class":"property","value":"'is_label'","descriptions":{"feature":["Feature","\n        The child feature"],"condition":["str","\n        The name of the conditional property"]},"index":102},{"items":[],"name":"z","expand":true,"class":"property","value":"0","index":103},null,null,null,null,{"items":[],"name":"function","expand":false,"class":"property","value":"lambda image: np.concatenate(get_field(image), axis=-1)","descriptions":{"function":["Callable[Image]","\n        Function that takes the current image as first input "]},"index":98},{"items":[],"name":"get_field","expand":true,"class":"property","value":"lambda image: (np.real(image), np.imag(image))","index":99},null,null,null,null,null,null,null,null,null,{"items":[120,121],"name":"SplitComplex","expand":true,"class":"feature","key":"features","type":"Lambda","description":" Calls a custom function on each image in the input.\n\n    Note that the property `function` needs to be wrapped in an\n    outer layer function. The outer layer function can depend on\n    other properties, while the inner layer function accepts an\n    image as input.\n\n    ","index":119},{"items":[],"name":"function","expand":false,"class":"property","value":"lambda image: np.concatenate(get_field(image), axis=-1)","descriptions":{"function":["Callable[Image]","\n        Function that takes the current image as first input "]},"index":120},{"items":[],"name":"get_field","expand":true,"class":"property","value":"lambda image: (np.real(image), np.imag(image))","index":121}]},"future":[]}}