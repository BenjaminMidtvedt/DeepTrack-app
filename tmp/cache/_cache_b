{"undoable":{"past":[[{"kind":"E","path":["items",109,"value"],"lhs":"np.random.ran","rhs":"np.random.rand"}],[{"kind":"E","path":["items",109,"value"],"lhs":"np.random.rand","rhs":"np.random.rand("}],[{"kind":"E","path":["items",109,"value"],"lhs":"np.random.rand(","rhs":"np.random.rand()"}],"@@easy-redux-undo/GROUPBEGIN",[{"kind":"A","path":["items"],"index":129,"item":{"kind":"N","rhs":{"items":[],"name":"Poisson","expand":true,"class":"feature","key":"noises","type":"Poisson","description":"Adds Poisson-distributed noise to an image\n\n    ","index":129}}},{"kind":"A","path":["items",70,"items"],"index":1,"item":{"kind":"N","rhs":129}}],"@@easy-redux-undo/GROUPEND","@@easy-redux-undo/GROUPBEGIN",[{"kind":"A","path":["items",70,"items"],"index":1,"item":{"kind":"D","lhs":129}},{"kind":"A","path":["items",9,"items"],"index":1,"item":{"kind":"N","rhs":129}}],"@@easy-redux-undo/GROUPEND",[{"kind":"A","path":["items"],"index":130,"item":{"kind":"N","rhs":{"items":[],"name":"","expand":true,"class":"property","value":"","index":130}}},{"kind":"A","path":["items",129,"items"],"index":0,"item":{"kind":"N","rhs":130}}],[{"kind":"E","path":["items",130,"expand"],"lhs":true,"rhs":false}],[{"kind":"E","path":["items",130,"name"],"lhs":"","rhs":"s"}],[{"kind":"E","path":["items",130,"name"],"lhs":"s","rhs":"sn"}],[{"kind":"E","path":["items",130,"name"],"lhs":"sn","rhs":"snr"}],[{"kind":"A","path":["items"],"index":131,"item":{"kind":"N","rhs":{"items":[],"name":"","expand":true,"class":"property","value":"","index":131}}},{"kind":"A","path":["items",129,"items"],"index":1,"item":{"kind":"N","rhs":131}}],[{"kind":"E","path":["items",130,"expand"],"lhs":false,"rhs":true}],[{"kind":"E","path":["items",130,"value"],"lhs":"","rhs":"4"}],[{"kind":"E","path":["items",130,"value"],"lhs":"4","rhs":"2"}],[{"kind":"E","path":["items",130,"value"],"lhs":"2","rhs":"1"}],[{"kind":"E","path":["items",130,"value"],"lhs":"1","rhs":"0"}],[{"kind":"E","path":["items",130,"value"],"lhs":"0","rhs":"0."}],[{"kind":"E","path":["items",130,"value"],"lhs":"0.","rhs":"0.1"}],[{"kind":"E","path":["items",130,"value"],"lhs":"0.1","rhs":"0.3"}],[{"kind":"E","path":["items",130,"value"],"lhs":"0.3","rhs":"0.5"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.7","rhs":"0."}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.","rhs":"0.5"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5","rhs":"0.5 "}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 ","rhs":"0.5 +"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 +","rhs":"0.5 + "}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + ","rhs":"0.5 +"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 +","rhs":"0.5 "}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 ","rhs":"0.5"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5","rhs":"1"}],[{"kind":"E","path":["items",99,"value"],"lhs":"1","rhs":"0"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0","rhs":"05"}],[{"kind":"E","path":["items",99,"value"],"lhs":"05","rhs":"0"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0","rhs":"0."}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.","rhs":"0.5"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5","rhs":"0.5 "}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 ","rhs":"0.5 +"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 +","rhs":"0.5 + "}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + ","rhs":"0.5 + n"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + n","rhs":"0.5 + np"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np","rhs":"0.5 + npr"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + npr","rhs":"0.5 + npra"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + npra","rhs":"0.5 + npr"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + npr","rhs":"0.5 + np"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np","rhs":"0.5 + np."}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np.","rhs":"0.5 + np.r"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np.r","rhs":"0.5 + np.ra"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np.ra","rhs":"0.5 + np.random"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np.random","rhs":"0.5 + np.random."}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np.random.","rhs":"0.5 + np.random.r"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np.random.r","rhs":"0.5 + np.random.ra"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np.random.ra","rhs":"0.5 + np.random.rand"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np.random.rand","rhs":"0.5 + np.random.rand("}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np.random.rand(","rhs":"0.5 + np.random.rand()"}],[{"kind":"E","path":["items",106,"value"],"lhs":"(0, 0, 256, 256)","rhs":"(0, 0, 1, 256)"}],[{"kind":"E","path":["items",106,"value"],"lhs":"(0, 0, 1, 256)","rhs":"(0, 0, 12, 256)"}],[{"kind":"E","path":["items",106,"value"],"lhs":"(0, 0, 12, 256)","rhs":"(0, 0, 128, 256)"}],[{"kind":"E","path":["items",106,"value"],"lhs":"(0, 0, 128, 256)","rhs":"(0, 0, 128, 1)"}],[{"kind":"E","path":["items",106,"value"],"lhs":"(0, 0, 128, 1)","rhs":"(0, 0, 128, 12)"}],[{"kind":"E","path":["items",106,"value"],"lhs":"(0, 0, 128, 12)","rhs":"(0, 0, 128, 128)"}],[{"kind":"E","path":["items",101,"value"],"lhs":"10","rhs":"6"}],[{"kind":"E","path":["items",130,"value"],"lhs":"0.5","rhs":"1"}],[{"kind":"E","path":["items",2,"expand"],"lhs":true,"rhs":false}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np.random.rand()","rhs":"0.5 + np.random.rand() "}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np.random.rand() ","rhs":"0.5 + np.random.rand() *"}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np.random.rand() *","rhs":"0.5 + np.random.rand() * "}],[{"kind":"E","path":["items",99,"value"],"lhs":"0.5 + np.random.rand() * ","rhs":"0.5 + np.random.rand() * 0"}],[{"kind":"E","path":["items",2,"expand"],"lhs":false,"rhs":true}],[{"kind":"E","path":["items",50,"value"],"lhs":"","rhs":"\""}],[{"kind":"E","path":["items",50,"value"],"lhs":"\"","rhs":"\"r"}],[{"kind":"E","path":["items",50,"value"],"lhs":"\"r","rhs":"\"re"}],[{"kind":"E","path":["items",50,"value"],"lhs":"\"re","rhs":"\"rel"}],[{"kind":"E","path":["items",50,"value"],"lhs":"\"rel","rhs":"\"relu"}],[{"kind":"E","path":["items",48,"value"],"lhs":"1","rhs":"2"}],[{"kind":"E","path":["items",45,"value"],"lhs":"(16, 32, 64, 128)","rhs":"(3, 32, 64, 128)"}],[{"kind":"E","path":["items",45,"value"],"lhs":"(3, 32, 64, 128)","rhs":"(32, 32, 64, 128)"}],[{"kind":"E","path":["items",45,"value"],"lhs":"(32, 32, 64, 128)","rhs":"(32, 3, 64, 128)"}],[{"kind":"E","path":["items",45,"value"],"lhs":"(32, 3, 64, 128)","rhs":"(32, , 64, 128)"}],[{"kind":"E","path":["items",45,"value"],"lhs":"(32, , 64, 128)","rhs":"(32, 6, 64, 128)"}],[{"kind":"E","path":["items",45,"value"],"lhs":"(32, 6, 64, 128)","rhs":"(32, 64, 64, 128)"}],[{"kind":"E","path":["items",45,"value"],"lhs":"(32, 64, 64, 128)","rhs":"(32, 64, 1, 128)"}],[{"kind":"E","path":["items",45,"value"],"lhs":"(32, 64, 1, 128)","rhs":"(32, 64, 12, 128)"}],[{"kind":"E","path":["items",45,"value"],"lhs":"(32, 64, 12, 128)","rhs":"(32, 64, 128, 128)"}],[{"kind":"E","path":["items",45,"value"],"lhs":"(32, 64, 128, 128)","rhs":"(32, 64, 128, 2)"}],[{"kind":"E","path":["items",45,"value"],"lhs":"(32, 64, 128, 2)","rhs":"(32, 64, 128, 25)"}],[{"kind":"E","path":["items",45,"value"],"lhs":"(32, 64, 128, 25)","rhs":"(32, 64, 128, 256)"}],[{"kind":"E","path":["items",46,"value"],"lhs":"(128, 128)","rhs":"(5, 128)"}],[{"kind":"E","path":["items",46,"value"],"lhs":"(5, 128)","rhs":"(51, 128)"}],[{"kind":"E","path":["items",46,"value"],"lhs":"(51, 128)","rhs":"(512, 128)"}],[{"kind":"E","path":["items",46,"value"],"lhs":"(512, 128)","rhs":"(512, 5)"}],[{"kind":"E","path":["items",46,"value"],"lhs":"(512, 5)","rhs":"(512, 51)"}],[{"kind":"E","path":["items",46,"value"],"lhs":"(512, 51)","rhs":"(512, 512)"}],[{"kind":"E","path":["items",47,"value"],"lhs":"(16, 16)","rhs":"(3, 16)"}],[{"kind":"E","path":["items",47,"value"],"lhs":"(3, 16)","rhs":"(32, 16)"}],[{"kind":"E","path":["items",47,"value"],"lhs":"(32, 16)","rhs":"(32, 3)"}],[{"kind":"E","path":["items",47,"value"],"lhs":"(32, 3)","rhs":"(32, 32)"}],[{"kind":"E","path":["items",50,"value"],"lhs":"\"relu","rhs":"\"relu2"}],[{"kind":"E","path":["items",50,"value"],"lhs":"\"relu2","rhs":"\"relu"}],[{"kind":"E","path":["items",50,"value"],"lhs":"\"relu","rhs":"\"relu\""}],[{"kind":"E","path":["items",1,"expand"],"lhs":true,"rhs":false}],[{"kind":"E","path":["items",2,"expand"],"lhs":true,"rhs":false}]],"present":{"items":[{"items":[1,2],"name":"","expand":true,"index":0},{"items":[3,4],"name":"Dataset","expand":false,"load":".dts","class":"root","grabbable":false,"index":1},{"items":[5,6,7],"name":"Model","expand":false,"load":".dtm","class":"root","grabbable":false,"index":2},{"items":[8,108,59],"name":"Image","expand":true,"class":"featureGroup","grabbable":false,"index":3},{"items":[],"name":"Label","expand":true,"class":"featureGroup","grabbable":false,"index":4},{"items":[],"name":"Preprocess","expand":true,"class":"featureGroup","grabbable":false,"index":5},{"items":[43],"name":"Network","expand":true,"class":"featureGroup","grabbable":false,"index":6},{"items":[],"name":"Postprocess","expand":true,"class":"featureGroup","grabbable":false,"index":7},{"items":[9,10],"name":"Microscope","expand":true,"class":"feature","key":"optics","type":"Microscope","description":"Image a sample using an optical system.\n\n    Wraps a feature-set defining a sample and a feature-set defining the optics.\n\n    ","index":8},{"items":[69,129],"name":"sample","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"sample":["Feature","\n        A feature-set resolving a list of images describing the sample to be imaged"],"objective":["Feature","\n        A feature-set defining the optical device that images the sample"]},"index":9},{"items":[98],"name":"objective","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"sample":["Feature","\n        A feature-set resolving a list of images describing the sample to be imaged"],"objective":["Feature","\n        A feature-set defining the optical device that images the sample"]},"index":10},null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,{"items":[32,33,34,35,36,37],"name":"Sphere","expand":true,"class":"feature","key":"scatterers","type":"Sphere","description":"Generates a spherical scatterer\n\n    ","index":31},{"items":[],"name":"radius","expand":true,"class":"property","value":"0.5e-6 + np.random.rand() * 1.5e-6 ","descriptions":{"radius":["float","\n        Radius of the sphere in meters."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":32},{"items":[],"name":"position","expand":true,"class":"property","value":"np.random.rand(2) * Fluorescence.output_region[2:]","descriptions":{"radius":["float","\n        Radius of the sphere in meters."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":33},{"items":[],"name":"z","expand":true,"class":"property","value":"0","descriptions":{"radius":["float","\n        Radius of the sphere in meters."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":34},{"items":[],"name":"value","expand":true,"class":"property","value":"1.0","descriptions":{"radius":["float","\n        Radius of the sphere in meters."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":35},{"items":[],"name":"position_unit","expand":true,"class":"property","value":"'pixel'","descriptions":{"radius":["float","\n        Radius of the sphere in meters."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":36},{"items":[],"name":"upsample","expand":true,"class":"property","value":"1","descriptions":{"radius":["float","\n        Radius of the sphere in meters."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":37},null,null,null,null,null,{"items":[44,45,46,47,48,49,50,51,52,53,54,55,56],"name":"UNet","expand":true,"class":"feature","key":"models","type":"UNet","description":"Creates and compiles a U-Net.\n\n    ","index":43},{"items":[],"name":"input_shape","expand":true,"class":"property","value":"(None, None, 1)","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."],"add_batch_dimension_on_resolve":["bool","\n        Whether to add a dimension before the first axis \n        before calling predict."]},"index":44},{"items":[],"name":"conv_layers_dimensions","expand":true,"class":"property","value":"(32, 64, 128, 256)","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."],"add_batch_dimension_on_resolve":["bool","\n        Whether to add a dimension before the first axis \n        before calling predict."]},"index":45},{"items":[],"name":"base_conv_layers_dimensions","expand":true,"class":"property","value":"(512, 512)","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."],"add_batch_dimension_on_resolve":["bool","\n        Whether to add a dimension before the first axis \n        before calling predict."]},"index":46},{"items":[],"name":"output_conv_layers_dimensions","expand":true,"class":"property","value":"(32, 32)","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."],"add_batch_dimension_on_resolve":["bool","\n        Whether to add a dimension before the first axis \n        before calling predict."]},"index":47},{"items":[],"name":"steps_per_pooling","expand":true,"class":"property","value":"2","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."],"add_batch_dimension_on_resolve":["bool","\n        Whether to add a dimension before the first axis \n        before calling predict."]},"index":48},{"items":[],"name":"number_of_outputs","expand":true,"class":"property","value":"1","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."],"add_batch_dimension_on_resolve":["bool","\n        Whether to add a dimension before the first axis \n        before calling predict."]},"index":49},{"items":[],"name":"output_activation","expand":true,"class":"property","value":"\"relu\"","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."],"add_batch_dimension_on_resolve":["bool","\n        Whether to add a dimension before the first axis \n        before calling predict."]},"index":50},{"items":[],"name":"loss","expand":true,"class":"property","value":"\"mae\"","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."],"add_batch_dimension_on_resolve":["bool","\n        Whether to add a dimension before the first axis \n        before calling predict."]},"index":51},{"items":[],"name":"layer_function","expand":true,"class":"property","value":"","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."],"add_batch_dimension_on_resolve":["bool","\n        Whether to add a dimension before the first axis \n        before calling predict."]},"index":52},{"items":[],"name":"optimizer","expand":true,"class":"property","value":"\"adam\"","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."],"add_batch_dimension_on_resolve":["bool","\n        Whether to add a dimension before the first axis \n        before calling predict."]},"index":53},{"items":[],"name":"metrics","expand":true,"class":"property","value":"","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."],"add_batch_dimension_on_resolve":["bool","\n        Whether to add a dimension before the first axis \n        before calling predict."]},"index":54},{"items":[],"name":"add_batch_dimension_on_resolve","expand":true,"class":"property","value":"","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."],"add_batch_dimension_on_resolve":["bool","\n        Whether to add a dimension before the first axis \n        before calling predict."]},"index":55},{"items":[],"name":"name","expand":true,"class":"property","value":"","descriptions":{"input_shape":["tuple of ints","\n        Size of the images to be analyzed."],"conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer during down-\n        and upsampling."],"base_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer at the base\n        of the unet, where the image is the most downsampled."],"output_conv_layers_dimensions":["tuple of ints","\n        Number of convolutions in each convolutional layer after the\n        upsampling."],"steps_per_pooling":["int","\n        Number of convolutional layers between each pooling and upsampling\n        step."],"number_of_outputs":["int","\n        Number of convolutions in output layer."],"output_activation":["str or keras activation","\n        The activation function of the output."],"loss":["str or keras loss function","\n        The loss function of the network."],"layer_function":["Callable[int] -> keras layer","\n        Function that returns a convolutional layer with convolutions\n        determined by the input argument. Can be use to futher customize the network."],"optimizer":["str or keras optimizer","\n        The optimizer of the model."],"add_batch_dimension_on_resolve":["bool","\n        Whether to add a dimension before the first axis \n        before calling predict."]},"index":56},{"items":[58],"name":"Poisson","expand":true,"class":"feature","key":"noises","type":"Poisson","description":"Adds Poisson-distributed noise to an image\n\n    ","index":57},{"items":[],"name":"snr","expand":true,"class":"property","value":"5 + np.random.rand() * 95","index":58},{"items":[60,61,65],"name":"ConditionalSetProperty","expand":true,"class":"feature","key":"features","type":"ConditionalSetProperty","description":" Conditionally overrides the properties of child features\n    \n    ","index":59},{"items":[62],"name":"feature","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"feature":["Feature","\n        The child feature"],"condition":["str","\n        The name of the conditional property"]},"index":60},{"items":[],"name":"condition","expand":true,"class":"property","value":"'is_label'","descriptions":{"feature":["Feature","\n        The child feature"],"condition":["str","\n        The name of the conditional property"]},"index":61},{"items":[63,64],"name":"Probability","expand":true,"class":"feature","key":"features","type":"Probability","description":" Resolves a feature with a certain probability\n\n    ","index":62},{"items":[57],"name":"feature","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"feature":["Feature","\n        Feature to resolve"],"probability":["float","\n        Probability to resolve"]},"index":63},{"items":[],"name":"probability","expand":true,"class":"property","value":"1","type":"float","descriptions":{"feature":["Feature","\n        Feature to resolve"],"probability":["float","\n        Probability to resolve"]},"index":64},{"items":[],"name":"probability","expand":true,"class":"property","value":"0","index":65},null,null,null,{"items":[70,71],"name":"Duplicate","expand":true,"class":"feature","key":"features","type":"Duplicate","description":"Resolves copies of a feature sequentially\n    Creates `num_duplicates` copies of the feature and resolves\n    them sequentially\n\n    ","index":69},{"items":[80],"name":"feature","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"feature":["Feature","\n        The feature to duplicate"],"num_duplicates":["int","\n        The number of duplicates to create"]},"index":70},{"items":[],"name":"num_duplicates","expand":true,"class":"property","value":"np.random.randint(4, 8)","type":"int","descriptions":{"feature":["Feature","\n        The feature to duplicate"],"num_duplicates":["int","\n        The number of duplicates to create"]},"index":71},null,null,null,null,null,null,null,null,{"items":[81,82,83,84,85,86,87],"name":"Ellipsoid","expand":true,"class":"feature","key":"scatterers","type":"Ellipsoid","description":"Generates an ellipsoidal scatterer\n\n    ","index":80},{"items":[],"name":"radius","expand":true,"class":"property","value":"(0.5e-6 + np.random.rand(2) * 1.5e-6 )","descriptions":{"radius":["float or array_like[float (, float, float)]","\n        Radius of the ellipsoid in meters. If only one value,\n        assume spherical."],"rotation":["float","\n        Rotation of the ellipsoid in about the x, y and z axis."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":81},{"items":[],"name":"rotation","expand":true,"class":"property","value":"np.random.rand(3) * 2 * np.pi","descriptions":{"radius":["float or array_like[float (, float, float)]","\n        Radius of the ellipsoid in meters. If only one value,\n        assume spherical."],"rotation":["float","\n        Rotation of the ellipsoid in about the x, y and z axis."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":82},{"items":[],"name":"position","expand":true,"class":"property","value":"np.random.rand(2) * Fluorescence.output_region[2:]","descriptions":{"radius":["float or array_like[float (, float, float)]","\n        Radius of the ellipsoid in meters. If only one value,\n        assume spherical."],"rotation":["float","\n        Rotation of the ellipsoid in about the x, y and z axis."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":83},{"items":[],"name":"z","expand":true,"class":"property","value":"0","descriptions":{"radius":["float or array_like[float (, float, float)]","\n        Radius of the ellipsoid in meters. If only one value,\n        assume spherical."],"rotation":["float","\n        Rotation of the ellipsoid in about the x, y and z axis."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":84},{"items":[],"name":"value","expand":true,"class":"property","value":"1.0","descriptions":{"radius":["float or array_like[float (, float, float)]","\n        Radius of the ellipsoid in meters. If only one value,\n        assume spherical."],"rotation":["float","\n        Rotation of the ellipsoid in about the x, y and z axis."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":85},{"items":[],"name":"position_unit","expand":true,"class":"property","value":"'meter'","descriptions":{"radius":["float or array_like[float (, float, float)]","\n        Radius of the ellipsoid in meters. If only one value,\n        assume spherical."],"rotation":["float","\n        Rotation of the ellipsoid in about the x, y and z axis."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":86},{"items":[],"name":"upsample","expand":true,"class":"property","value":"1","descriptions":{"radius":["float or array_like[float (, float, float)]","\n        Radius of the ellipsoid in meters. If only one value,\n        assume spherical."],"rotation":["float","\n        Rotation of the ellipsoid in about the x, y and z axis."],"position":["array_like of length 2 or 3","\n        The position of the  particle. Third index is optional, \n        and represents the position in the direction normal to the\n        camera plane."],"z":["float","\n        The position in the direction normal to the\n        camera plane. Used if `position` is of length 2."],"value":["float","\n        A default value of the characteristic of the particle. Used by\n        optics unless a more direct property is set (eg. `refractive_index`\n        for `Brightfield` and `intensity` for `Fluorescence`)."],"position_unit":["\"meter\" or \"pixel\"","\n        The unit of the provided position property."]},"index":87},null,null,null,{"items":[92,93],"name":"Probability","expand":true,"class":"feature","key":"features","type":"Probability","description":" Resolves a feature with a certain probability\n\n    ","index":91},{"items":[],"name":"feature","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"feature":["Feature","\n        Feature to resolve"],"probability":["float","\n        Probability to resolve"]},"index":92},{"items":[],"name":"probability","expand":true,"class":"property","value":"1","type":"float","descriptions":{"feature":["Feature","\n        Feature to resolve"],"probability":["float","\n        Probability to resolve"]},"index":93},null,{"items":[91],"name":"feature","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"feature":["Feature","\n        The child feature"],"condition":["str","\n        The name of the conditional property"]},"index":95},{"items":[],"name":"condition","expand":true,"class":"property","value":"'is_label'","descriptions":{"feature":["Feature","\n        The child feature"],"condition":["str","\n        The name of the conditional property"]},"index":96},{"items":[],"name":"probability","expand":true,"class":"property","value":"0","index":97},{"items":[99,100,101,102,103,104,105,106,107],"name":"Fluorescence","expand":true,"class":"feature","key":"optics","type":"Fluorescence","description":"Optical device for fluorescenct imaging\n\n    Images samples by creating a discretized volume, where each pixel \n    represents the intensity of the light emitted by fluorophores in\n    the the voxel.  \n\n    ","index":98},{"items":[],"name":"NA","expand":true,"class":"property","value":"0.5 + np.random.rand() * 0","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":99},{"items":[],"name":"wavelength","expand":true,"class":"property","value":"6.6e-07","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":100},{"items":[],"name":"magnification","expand":true,"class":"property","value":"6","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":101},{"items":[],"name":"resolution","expand":true,"class":"property","value":"(1e-06, 1e-06, 1e-06)","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":102},{"items":[],"name":"refractive_index_medium","expand":true,"class":"property","value":"1.33","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":103},{"items":[],"name":"upscale","expand":true,"class":"property","value":"2","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":104},{"items":[],"name":"padding","expand":true,"class":"property","value":"(10, 10, 10, 10)","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":105},{"items":[],"name":"output_region","expand":true,"class":"property","value":"(0, 0, 128, 128)","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":106},{"items":[125],"name":"pupil","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"NA":["float","\n        The NA of the limiting aperature."],"wavelength":["float","\n        The wavelength of the scattered light in meters."],"magnification":["float","\n        The magnification of the optical system."],"resolution":["array_like[float (, float, float)]","\n        The distance between pixels in the camera. A third value can be\n        included to define the resolution in the z-direction."],"refractive_index_medium":["float","\n        The refractive index of the medium."],"upscale":["int","\n        Upscales the pupil function for a more accurate result."],"padding":["array_like[int, int, int, int]","\n        Pads the sample volume with zeros to avoid edge effects."],"output_region":["array_like[int, int, int, int]","\n        The region of the image to output (x,y,width,height). Default\n        None returns entire image."],"pupil":["Feature","\n        A feature-set resolving the pupil function at focus. The feature-set\n        receive an unaberrated pupil as input."]},"index":107},{"items":[109],"name":"Offset","expand":true,"class":"feature","key":"noises","type":"Offset","description":" Adds a constant value to an image\n    ","index":108},{"items":[],"name":"offset","expand":true,"class":"property","value":"np.random.rand()","descriptions":{"offset":["float","\n        The value to add to the image"]},"index":109},{"items":[111,112,113],"name":"SphericalAberration","expand":true,"class":"feature","key":"aberrations","type":"SphericalAberration","description":" Zernike polynomial with n=4, m=0.\n    \n    ","index":110},{"items":[],"name":"coefficient","expand":true,"class":"property","value":"np.random.randn()","descriptions":{"coefficient":["float","\n        The coefficient of the polynomial"],"n":["int or list of ints","\n        The zernike polynomial numbers. "],"m":["int or list of ints","\n        The zernike polynomial numbers. "]},"index":111},{"items":[],"name":"n","expand":true,"class":"property","value":"","descriptions":{"coefficient":["float","\n        The coefficient of the polynomial"],"n":["int or list of ints","\n        The zernike polynomial numbers. "],"m":["int or list of ints","\n        The zernike polynomial numbers. "]},"index":112},{"items":[],"name":"m","expand":true,"class":"property","value":"","descriptions":{"coefficient":["float","\n        The coefficient of the polynomial"],"n":["int or list of ints","\n        The zernike polynomial numbers. "],"m":["int or list of ints","\n        The zernike polynomial numbers. "]},"index":113},{"items":[115,116,117],"name":"Astigmatism","expand":true,"class":"feature","key":"aberrations","type":"Astigmatism","description":" Zernike polynomial with n=2, m=2.\n    \n    ","index":114},{"items":[],"name":"coefficient","expand":true,"class":"property","value":"np.random.randn()","descriptions":{"coefficient":["float","\n        The coefficient of the polynomial"],"n":["int or list of ints","\n        The zernike polynomial numbers. "],"m":["int or list of ints","\n        The zernike polynomial numbers. "]},"index":115},{"items":[],"name":"n","expand":true,"class":"property","value":"","descriptions":{"coefficient":["float","\n        The coefficient of the polynomial"],"n":["int or list of ints","\n        The zernike polynomial numbers. "],"m":["int or list of ints","\n        The zernike polynomial numbers. "]},"index":116},{"items":[],"name":"m","expand":true,"class":"property","value":"","descriptions":{"coefficient":["float","\n        The coefficient of the polynomial"],"n":["int or list of ints","\n        The zernike polynomial numbers. "],"m":["int or list of ints","\n        The zernike polynomial numbers. "]},"index":117},{"items":[119,120,121],"name":"ObliqueAstigmatism","expand":true,"class":"feature","key":"aberrations","type":"ObliqueAstigmatism","description":" Zernike polynomial with n=2, m=-2.\n    \n    ","index":118},{"items":[],"name":"coefficient","expand":true,"class":"property","value":"np.random.randn()","descriptions":{"coefficient":["float","\n        The coefficient of the polynomial"],"n":["int or list of ints","\n        The zernike polynomial numbers. "],"m":["int or list of ints","\n        The zernike polynomial numbers. "]},"index":119},{"items":[],"name":"n","expand":true,"class":"property","value":"","descriptions":{"coefficient":["float","\n        The coefficient of the polynomial"],"n":["int or list of ints","\n        The zernike polynomial numbers. "],"m":["int or list of ints","\n        The zernike polynomial numbers. "]},"index":120},{"items":[],"name":"m","expand":true,"class":"property","value":"","descriptions":{"coefficient":["float","\n        The coefficient of the polynomial"],"n":["int or list of ints","\n        The zernike polynomial numbers. "],"m":["int or list of ints","\n        The zernike polynomial numbers. "]},"index":121},{"items":[123,124],"name":"Probability","expand":true,"class":"feature","key":"features","type":"Probability","description":" Resolves a feature with a certain probability\n\n    ","index":122},{"items":[110,114,118],"name":"feature","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"feature":["Feature","\n        Feature to resolve"],"probability":["float","\n        Probability to resolve"]},"index":123},{"items":[],"name":"probability","expand":true,"class":"property","value":"1","type":"float","descriptions":{"feature":["Feature","\n        Feature to resolve"],"probability":["float","\n        Probability to resolve"]},"index":124},{"items":[126,127,128],"name":"ConditionalSetProperty","expand":true,"class":"feature","key":"features","type":"ConditionalSetProperty","description":" Conditionally overrides the properties of child features\n    \n    ","index":125},{"items":[122],"name":"feature","expand":true,"class":"featureGroup","value":"","type":"deeptrack.features.Feature","descriptions":{"feature":["Feature","\n        The child feature"],"condition":["str","\n        The name of the conditional property"]},"index":126},{"items":[],"name":"condition","expand":true,"class":"property","value":"'is_label'","descriptions":{"feature":["Feature","\n        The child feature"],"condition":["str","\n        The name of the conditional property"]},"index":127},{"items":[],"name":"probability","expand":true,"class":"property","value":"0","index":128},{"items":[130,131],"name":"Poisson","expand":true,"class":"feature","key":"noises","type":"Poisson","description":"Adds Poisson-distributed noise to an image\n\n    ","index":129},{"items":[],"name":"snr","expand":true,"class":"property","value":"1","index":130},{"items":[],"name":"","expand":true,"class":"property","value":"","index":131}]},"future":[]}}